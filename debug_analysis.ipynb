{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "from dataset_loader import DatasetLoader\n",
    "from annotations_loader import AnnotationsLoader\n",
    "\n",
    "def display_img(img, BGR=False):\n",
    "    if isinstance(img, str):\n",
    "        display_img(cv2.imread(img))\n",
    "        return\n",
    "    plt.figure(dpi=150)\n",
    "    if BGR:\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/proj/brizk/output/'\n",
    "faces_dir = os.path.join(*[home_dir, 'retinaface'])\n",
    "attention_dir = os.path.join(*[home_dir, 'attentiontarget'])\n",
    "videos_loader = DatasetLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    video = next(videos_loader)\n",
    "    video_name = os.path.basename(video.filepath).split('.')[0]\n",
    "    ds = videos_loader.current_ds\n",
    "    print(f'Processing {video_name} @ {ds}')\n",
    "    try:\n",
    "        annotations = AnnotationsLoader(\n",
    "            ds, video_name, faces_dir=faces_dir, attention_dir=attention_dir,\n",
    "            faces_confidence_thres = 0.95\n",
    "        )\n",
    "        break\n",
    "    except FileNotFoundError:\n",
    "        print(f'Annotations not available yet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping over frames annotations (Targeting only at least of 2 attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = AnnotationsLoader(\n",
    "            ds, video_name, faces_dir=faces_dir, attention_dir=attention_dir,\n",
    "            faces_confidence_thres = 0.95\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passed = 0\n",
    "faces_num_thres = 2\n",
    "num_of_faces = 0\n",
    "\n",
    "while(True):\n",
    "    annotation = next(annotations)\n",
    "    if annotation is None:\n",
    "        break\n",
    "    num_of_faces = len(annotation['faces'])\n",
    "    if num_of_faces > faces_num_thres:\n",
    "        break\n",
    "    passed += 1\n",
    "\n",
    "if num_of_faces > faces_num_thres:\n",
    "    print('Discarded', passed, 'frames')\n",
    "    frame_num = annotation['frame']\n",
    "    print('Now at frame', frame_num)\n",
    "else:\n",
    "    print(f'Did not found any simulatanious more than {faces_num_thres} faces in video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation['faces']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_face_center(head_box):\n",
    "    return [\n",
    "        head_box[0] + (head_box[2] - head_box[0])//2,\n",
    "        head_box[1] + (head_box[3] - head_box[1])//2\n",
    "    ]\n",
    "\n",
    "def get_attention_vector(head_box, observation_coordinates):\n",
    "    face_center = calc_face_center(head_box)\n",
    "    return np.append(face_center, observation_coordinates)\n",
    "\n",
    "def calc_line_angle(line):\n",
    "    return np.degrees(np.arctan2(-(line[3]-line[1]), line[2]-line[0]))\n",
    "\n",
    "def calc_relative_angle(vectors, verbose=False):\n",
    "    angles = np.array([calc_line_angle(l) for l in vectors])\n",
    "    if verbose:\n",
    "        print('Angles:', angles)\n",
    "    return abs(angles[0] - angles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_img = cv2.cvtColor(video[frame_num], cv2.COLOR_BGR2RGB)\n",
    "print('queried frame_num', frame_num)\n",
    "print('current frame', video.current_frame_num)\n",
    "height, width, _ = frame_img.shape\n",
    "faces_per_frame = annotation['faces']\n",
    "attention_per_frame = annotation['attention']\n",
    "annotation['faces']\n",
    "\n",
    "display_img(frame_img)\n",
    "\n",
    "colors = [(255, 0, 0), (0, 0, 255), (0, 255, 0)]\n",
    "attention_vectors = np.zeros((num_of_faces,4), dtype=np.int32)\n",
    "\n",
    "for i in faces_per_frame.index:\n",
    "    head_box = np.array(\n",
    "        [faces_per_frame.loc[i,'left'], faces_per_frame.loc[i,'top'],\n",
    "         faces_per_frame.loc[i,'right'], faces_per_frame.loc[i,'bottom']]\n",
    "    ).astype(np.int32)\n",
    "    \n",
    "    observation_coordinates = attention_per_frame.loc[i, 'observation_coordinates']\n",
    "    print('Observation is at', observation_coordinates)\n",
    "\n",
    "    raw_hm = attention_per_frame.loc[i, 'raw_hm']\n",
    "    inout = attention_per_frame.loc[i, 'inout']\n",
    "    norm_map = transform.resize(raw_hm, (height, width)) - inout\n",
    "\n",
    "\n",
    "    vector_of_attention = get_attention_vector(head_box, observation_coordinates)\n",
    "    print('vector of attention:', vector_of_attention)\n",
    "    cv2.line(frame_img, vector_of_attention[:2], vector_of_attention[2:], colors[i], 4)\n",
    "    attention_vectors[i] = vector_of_attention\n",
    "    \n",
    "    cv2.rectangle(frame_img, (head_box[0], head_box[1]), (head_box[2], head_box[3]), colors[i], 4)\n",
    "    cv2.circle(frame_img, observation_coordinates, int(height/50.0), colors[i], 4)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    rect = patches.Rectangle((head_box[0], head_box[1]), head_box[2]-head_box[0], head_box[3]-head_box[1], linewidth=2, edgecolor=(0,1,0), facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    circ = patches.Circle((observation_coordinates[0], observation_coordinates[1]), height/50.0, facecolor=(0,1,0), edgecolor='none')\n",
    "    ax.add_patch(circ)\n",
    "    \n",
    "    plt.imshow(norm_map, cmap = 'jet', alpha=0.2, vmin=0, vmax=255)\n",
    "    # Grayscale then Otsu's threshold\n",
    "    gray = norm_map.copy()\n",
    "    gray[gray < 0] = 0\n",
    "    gray = gray.astype(np.uint8)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "    # Find contours\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        # print('contour shape', c.shape)\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        cv2.rectangle(frame_img, (x, y), (x + w, y + h), colors[i], 10)\n",
    "        print('rect bounds', x, y, w, h)\n",
    "        \n",
    "    plt.plot((observation_coordinates[0],(head_box[0]+head_box[2])/2), (observation_coordinates[1],(head_box[1]+head_box[3])/2), '-', color=(0,1,0,1))\n",
    "display_img(frame_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing two vectors looking opposite to each other\n",
    "attention_vectors_dump = attention_vectors.copy()\n",
    "attention_vectors_dump[1] = attention_vectors_dump[0].copy()\n",
    "tmp = attention_vectors_dump[0][:2].copy()\n",
    "attention_vectors_dump[0][:2] = attention_vectors_dump[0][2:].copy()\n",
    "attention_vectors_dump[0][2:] = tmp\n",
    "print(attention_vectors_dump)\n",
    "calc_relative_angle(attention_vectors_dump, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attention_vectors)\n",
    "calc_relative_angle(attention_vectors, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('retina_face')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faec6b7559de2b045bda80a9afcf29ca164f2f5fedec1d0a28853338c5a0785b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
